# ğŸ›° Deformable Attention Mechanisms Applied to Remotely Sensed Images

This repository contains the data and resources needed to apply **Deformable DETR** (Zhu et al., 2021) to optical and SAR remoteâ€‘sensing imagery and to benchmark it against a wide range of modern detectors.

<div align="center" style="border: 2px solid black; padding: 10px; background-color: #f8f8f8;">
    <img src="assets/GITHUB_COVER.PNG" alt="Project banner" width="650">
</div>

## ğŸ“Š Notebooks for Benchmarking

For each dataset (**Pleiades Aircraft** and **SSDD Ship Detection**), we provide Google Colab notebooks that fineâ€‘tune and evaluate the following detectors:

- **DN-DETR** â€“ *DETR with DeNoising anchors for faster convergence* (Li et al., 2022)
- **Conditional DETR** â€“ *Conditional crossâ€‘attention queries* (Meng et al., 2021)
- **DAB-DETR** â€“ *Dynamic Anchor Boxes* (Liu et al., 2022)
- **Deformable DETR** â€“ *Multiâ€‘scale deformable attention* (Zhu et al., 2021)
- **DETR** â€“ *Baseline transformer detector* (Carion et al., 2020)
- **YOLOÂ V10** â€“ *Oneâ€‘stage CNN detector* (Redmon et al., 2016)
- **RetinaNet** â€“ *Focalâ€‘loss oneâ€‘stage detector* (Lin et al., 2017)
- **FasterÂ Râ€‘CNN** â€“ *Twoâ€‘stage regionâ€‘proposal detector* (Ren et al., 2015)

Each model comes with two notebooks:
1. **TrainingÂ / ValidationÂ / Testing** â€“ full endâ€‘toâ€‘end pipeline.
2. **Quick Inference** â€“ load a fineâ€‘tuned checkpoint and run predictions on a folder of images.

---
## ğŸ“ Repository Structure

The proposed notebooks are organised as pairs: a *full pipeline* notebook and a *quick inference* notebook for every detector listed aboveÂ â€” 20 notebooks in total.

You can download the corresponding fineâ€‘tuned checkpoints under **[Fineâ€‘Tuned Models](https://drive.google.com/drive/u/1/folders/1xf-vNriat8YUJQGu-fedciORcqXCzzW6?usp=sharing)**. *NB:* unzip the DETR and DeformableÂ DETR weights before using them in the inference notebooks (folder: `Predictions`).

---
## ğŸ—ºï¸ Data to Be Used

This Google Drive folder **[Datasets](https://drive.google.com/drive/folders/1-8UDTKH-A7PerjXUXKDAXtTWKYRdj7IS?usp=sharing)** hosts the two datasets (optical and SAR) employed for training, validation and testing.

---
## ğŸ“ˆ Workflow Diagram of DeformableÂ DETR

The diagram below summarises the architecture of **DeformableÂ DETR**. It highlights the CNN backbone, the multiâ€‘scale deformableâ€‘attention modules and the Transformer decoder that predicts object classes and bounding boxes.

<div align="center" style="border: 2px solid black; padding: 10px; background-color: #f8f8f8;">
    <img src="assets/Deformable-DETR.png" alt="Workflow-DEFORMABLE-DETR" width="650">
</div>

---
## â–¶ï¸ Execution Instructions

Open any notebook in **Google Colab**, switch the runtime to *GPU*, andÂ â€” for best performanceÂ â€” choose an **NVIDIAÂ A100** if available.

---
## ğŸ§ª Testing Phase

The testing stage includes:
1. Visualising predictions.
2. Computing the following metrics:
   - **Precision**
   - **Recall**
   - **F1â€‘Score**
   - **mAP@50**
   - **mAP@75**
   - **mAP@[0.5:0.95]**

---
## ğŸ† Metric Results for 12Â EpochsÂ (%)

Performance of **DeformableÂ DETR** after 12Â epochs on both datasets.

### Pleiades Aircraft Dataset

| Model                 | Training TimeÂ (s) | Precision | Recall | F1â€‘Score | mAP@50 | mAP@75 | mAP@[0.5:0.95] |
|-----------------------|-------------------|-----------|--------|----------|--------|--------|----------------|
| **RetinaNet**         | 719.46            | 80.80     | 73.30  | 76.87    | 74.76  | 69.56  | 55.80          |
| **Faster R-CNN**      | 435.22            | 93.33     | 93.33  | 93.33    | 81.66  | 78.97  | 73.77          |
| **YOLO V10**          | 365.32            | 96.34     | 91.43  | 93.82    | 97.34  | 76.00  | 65.36          |
| **DETR**              | 327.34            | 93.21     | 90.35  | 91.19    | 80.05  | 78.46  | 73.44          |
| **DN-DETR**           | 354.15            | 92.54     | 87.60  | 89.90    | 83.16  | 80.14  | 73.81          |
| **Conditional DETR**  | 338.93            | 94.01     | 88.48  | 91.10    | 83.84  | 82.26  | 73.98          |
| **DAB-DETR**          | 329.36            | 95.23     | 90.06  | 92.57    | 95.14  | 87.53  | 74.19          |
| **Deformable DETR**   | **306.53**        | **97.76** | **92.62** | **95.12** | **98.42** | **89.42** | **76.75** |

---

### SSDD SAR Dataset

| Model                 | Training TimeÂ (s) | Precision | Recall | F1â€‘Score | mAP@50 | mAP@75 | mAP@[0.5:0.95] |
|-----------------------|-------------------|-----------|--------|----------|--------|--------|----------------|
| **RetinaNet**         | 3997.13           | 83.85     | 83.13  | 82.80    | 86.75  | 78.02  | 64.54          |
| **Faster R-CNN**      | 3452.22           | 90.36     | 87.23  | 88.77    | 91.61  | 73.93  | 62.53          |
| **YOLO V10**          | 3750.52           | 94.05     | 90.31  | 92.14    | 96.49  | 81.49  | 75.44          |
| **DETR**              | 3583.12           | 86.31     | 89.21  | 87.74    | 95.42  | 84.12  | 73.86          |
| **DN-DETR**           | 3834.89           | 90.54     | 91.36  | 90.95    | 92.18  | 84.14  | 73.18          |
| **Conditional DETR**  | 3576.29           | 94.01     | 89.19  | 91.54    | 94.63  | 86.78  | 74.89          |
| **DAB-DETR**          | 3489.27           | 95.23     | 92.49  | 93.84    | 96.14  | 87.89  | 74.54          |
| **Deformable DETR**   | **3370.16**       | **96.26** | **92.88** | **94.54** | **97.31** | **88.66** | **76.14** |
